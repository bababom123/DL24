{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:51.437221700Z",
     "start_time": "2024-11-20T10:20:51.420218400Z"
    }
   },
   "outputs": [],
   "source": [
    "from FusionNet import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:51.492945800Z",
     "start_time": "2024-11-20T10:20:51.436222Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 1\n",
    "img_size = 256\n",
    "lr = 0.0002\n",
    "epoch = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:51.493946800Z",
     "start_time": "2024-11-20T10:20:51.452947Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "train_img_dir = \"train/\"\n",
    "dir = os.path.join(train_img_dir + '.ipynb_checkpoints')\n",
    "if os.path.exists(dir) and os.path.isdir(dir):\n",
    "        shutil.rmtree(dir)\n",
    "train_img_data = dset.ImageFolder(root=train_img_dir, transform = transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ])) #edited\n",
    "train_img_batch = data.DataLoader(train_img_data, batch_size=batch_size,\n",
    "                            shuffle=False , num_workers=2) #edited\n",
    "\n",
    "val_img_dir = \"val/\"\n",
    "dir = os.path.join(val_img_dir + '.ipynb_checkpoints')\n",
    "if os.path.exists(dir) and os.path.isdir(dir):\n",
    "        shutil.rmtree(dir)\n",
    "val_img_data = dset.ImageFolder(root=val_img_dir, transform = transforms.Compose([\n",
    "                                            transforms.ToTensor(),\n",
    "                                            ])) #edited\n",
    "val_img_batch = data.DataLoader(val_img_data, batch_size=batch_size,\n",
    "                            shuffle=False, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:52.334491200Z",
     "start_time": "2024-11-20T10:20:51.465948200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating FusionNet------\n"
     ]
    }
   ],
   "source": [
    "generator = nn.DataParallel(FusionGenerator(3,3,64),device_ids=[0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:52.636729400Z",
     "start_time": "2024-11-20T10:20:52.336481200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackw\\AppData\\Local\\Temp\\ipykernel_38412\\4244458258.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  generator = torch.load('./model/model_fusionnet.pkl')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------model restored--------\n"
     ]
    }
   ],
   "source": [
    "#torch.nn.Module.dump_patches = True\n",
    "try:\n",
    "    generator = torch.load('./model/model_fusionnet.pkl')\n",
    "    print(\"\\n--------model restored--------\\n\")\n",
    "except:\n",
    "    print(\"\\n--------model not restored--------\\n\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:20:52.682536300Z",
     "start_time": "2024-11-20T10:20:52.638704900Z"
    }
   },
   "outputs": [],
   "source": [
    "# loss function & optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "gen_optimizer = torch.optim.Adam(generator.parameters(),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:25:35.212939100Z",
     "start_time": "2024-11-20T10:20:52.656224800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 0\n",
      "tensor(0.1532, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 100\n",
      "tensor(0.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 200\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 300\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 400\n",
      "tensor(0.0516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 500\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 600\n",
      "tensor(0.0479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 700\n",
      "tensor(0.0483, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 800\n",
      "tensor(0.0527, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 900\n",
      "tensor(0.0543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1000\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1100\n",
      "tensor(0.0317, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1200\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1300\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1400\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1500\n",
      "tensor(0.0369, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1600\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1700\n",
      "tensor(0.0567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1800\n",
      "tensor(0.0286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "49 1900\n",
      "tensor(0.0336, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 0\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 100\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 200\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 300\n",
      "tensor(0.0548, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 400\n",
      "tensor(0.0510, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 500\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 600\n",
      "tensor(0.0468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 700\n",
      "tensor(0.0475, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 800\n",
      "tensor(0.0520, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 900\n",
      "tensor(0.0519, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1000\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1100\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1200\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1300\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1400\n",
      "tensor(0.0406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1500\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1600\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1700\n",
      "tensor(0.0733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "50 1800\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 18\u001B[0m\n\u001B[0;32m     14\u001B[0m satel_image, label_image \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mchunk(image, chunks\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m) \u001B[38;5;66;03m#image.size() = [1,3,256,512], 1=batch size, 3 = number of channel\u001B[39;00m\n\u001B[0;32m     16\u001B[0m gen_optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 18\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43msatel_image\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#edited\u001B[39;00m\n\u001B[0;32m     19\u001B[0m y_ \u001B[38;5;241m=\u001B[39m label_image\u001B[38;5;241m.\u001B[39mcuda() \u001B[38;5;66;03m#edited\u001B[39;00m\n\u001B[0;32m     20\u001B[0m y \u001B[38;5;241m=\u001B[39m generator\u001B[38;5;241m.\u001B[39mforward(x)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "try:\n",
    "    file = open('./fusionnet_mse_fu_loss', 'r')\n",
    "    i = len(file.readlines()) + 1\n",
    "    file.close()\n",
    "except:\n",
    "    i = 1\n",
    "\n",
    "file = open('./fusionnet_mse_fu_loss', 'a')\n",
    "\n",
    "while i != epoch:\n",
    "    for _,(image,label) in enumerate(train_img_batch):\n",
    "        satel_image, label_image = torch.chunk(image, chunks=2, dim=3) #image.size() = [1,3,256,512], 1=batch size, 3 = number of channel\n",
    "        \n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        x = satel_image.cuda() #edited\n",
    "        y_ = label_image.cuda() #edited\n",
    "        y = generator.forward(x)\n",
    "        \n",
    "        loss = loss_func(y,y_)\n",
    "        loss.backward()\n",
    "        gen_optimizer.step()               \n",
    "        \n",
    "        if _ % 100 == 0 :\n",
    "            print(i,_)\n",
    "            print(loss)\n",
    "            file.write(str(loss)+\"\\n\")\n",
    "            v_utils.save_image(y.cpu().data,\"./result_train/gen_image_{}_{}.png\".format(i,_))\n",
    "            torch.save(generator,'./model/model_fusionnet.pkl')\n",
    "    i+=1\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T10:25:35.214938900Z"
    }
   },
   "outputs": [],
   "source": [
    "file.write(str(loss)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:25:35.224938Z",
     "start_time": "2024-11-20T10:25:35.216938900Z"
    }
   },
   "outputs": [],
   "source": [
    "# validate\n",
    "generator = torch.load('./model/model_fusionnet.pkl')\n",
    "\n",
    "#,map_location=lambda storage, loc: storage.cuda())\n",
    "\n",
    "\n",
    "for _,(image,label) in enumerate(val_img_batch):\n",
    "    satel_image, label_image = torch.chunk(image, chunks=2, dim=3) \n",
    "    print(_)\n",
    "    x = satel_image\n",
    "    y_ = label_image\n",
    "    y = generator.forward(x)\n",
    "\n",
    "    v_utils.save_image(y.cpu().data,\"./result_val/gen_image_{}.png\".format(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T10:25:35.218946400Z"
    }
   },
   "outputs": [],
   "source": [
    "val_img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T10:25:35.219938700Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
